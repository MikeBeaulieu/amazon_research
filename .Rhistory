user <- c("A2D1LPEUCTNT8X", "A2D1LPEUCTNT9Z", "ADDDp")
mapply(get_review_url, user, list(1:3, 1:2))
mapply(get_review_url, user, list(1:3, 1:2, 1:4))
reviews <- 3662
user
user <- "A2D1LPEUCTNT8X"
end <- get_review_url(user, page_num)
end
page_num <- floor(reviews/10)
end <- get_review_url(user, page_num)
end
last_html <- html(end)
last_page <- last_html %>%
html_node(xpath = "//b[text() = 'Page:']/a[past()]") %>%
html_text()
last_page <- last_html %>%
html_node(xpath = "//b[text() = 'Page:']/a[last()]") %>%
html_text()
last_page <- last_html %>%
html_node(xpath = "//b[text() = 'Page:']/a") %>%
html_text()
class(last_html)
last_page <- last_html %>%
html_node(xpath = "//b[text() = 'Page:']") %>%
html_text()
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_nodes(xpath = "//b[text() = 'Page:']") %>%
html_text()
last_page
last_page <- last_html %>%
html_nodes(xpath = "//b[text() = 'Page:']/a[last()]") %>%
html_text()
last_page
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_nodes(xpath = "//b[text() = 'Page:']/a") %>%
html_text()
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a") %>%
html_text()
last_page
?html_node
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a") %>%
html_text()
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text()
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
get_last_page <- function(user, reviews) {
# starting page number
page_num <- floor(reviews/10)
# get url
end <- get_review_url(user, page_num)
# grab the html
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
return(last_page)
}
pages$url_name[1]
pages$url_name[1:3]
last_pages <- mapply(get_last_page, pages$url_name[1:3],  pages$Reviews[1:3])
review <- pages$Reviews[1:3] %>%
str_replace_all(",", "") %>%
as.numeric()
last_pages <- mapply(get_last_page, pages$url_name[1:3],  review)
last_pages <- mapply(get_last_page, pages$url_name[1:3],  review)
last_pages <- lapply(pages$url_name[1:3], get_last_page, review)
as.list(1:3)
mapply(floor, review/10)
mapply(floor, review/10, SIMPLIFY = F)
initial_last_page <- function(user, reviews){
# starting page number
page_num <- mapply(floor, reviews/10, SIMPLIFY = F)
# get url
end <- mapply(get_review_url, as.list(user), pag_num)
return(end)
}
review
last_pages <- initial_last_page(pages$url_name, review)
# create all initial last page url's
initial_last_page <- function(user, reviews){
# starting page number
page_num <- mapply(floor, reviews/10, SIMPLIFY = F)
# get url
end <- mapply(get_review_url, as.list(user), page_num)
return(end)
}
last_pages <- initial_last_page(pages$url_name, review)
user
last_pages <- initial_last_page(pages$url_name[1:3], review)
last_page
last_pages
get_last_page <- function(end) {
# grab the html
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
return(last_page)
}
final_page <- lapply(last_pages, get_last_page)
get_last_page(last_pages[1])
get_last_page(last_pages[2])
last_html <- last_pages[1]
last_html
last_html <- last_pages[2]
last_html
last_html <- html(end)
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
last_html <- last_pages[1]
last_html <- html(end)
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
last_html <- last_pages[2]
last_html <- html(end)
end <- last_pages[2]
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
end <- last_pages[1]
last_html <- html(end)
last_page <- last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
end <- last_pages[2]
last_html <- html(end)
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text()
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric()
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric() %>%
.[length(.)]
get_last_page <- function(end) {
# grab the html
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric() %>%
.[length(.)]
return(last_page)
}
final_page <- lapply(last_pages, get_last_page)
final_page
last_pages
end <- last_pages[2]
end
last_html <- html(end)
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
as.numeric() %>%
.[length(.)]
last_page
# get last page of reviews
get_last_page <- function(end) {
# grab the html
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() %>%
# as.numeric() %>%
.[length(.)]
return(last_page)
}
final_page <- lapply(last_pages, get_last_page)
final_page
get_last_page <- function(end) {
# grab the html
last_html <- html(end)
# find the last listed page number, and we'll use that
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text() #%>%
# as.numeric() %>%
# .[length(.)]
return(last_page)
}
lapply(last_pages, get_last_page)
end <- last_pages[1]
end
last_html <- html(end)
last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text()
last_page <- last_html %>%
html_nodes(xpath = "//b[contains(text(),'Page:')]/a") %>%
html_text()
last_page
last_html
GET(end)
last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a") %>%
html_text()
end <- last_pages[1]
last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a") %>%
html_text()
last_html %>%
html_node(xpath = "//b[contains(text(),'Page:')]/a[last()]") %>%
html_text()
lapply(review/10, floor)
initial_last_page <- function(user, reviews){
# starting page number
page_num <- mapply(floor, reviews/10)
return(end)
}
initial_last_page <- function(reviews){
# starting page number
page_num <- mapply(floor, reviews/10)
return(end)
}
initial_last_page(review)
initial_last_page <- function(reviews){
# starting page number
page_num <- mapply(floor, reviews/10)
return(page_num)
}
initial_last_page(review)
pages$Reviews <- pages$Reviews %>%
str_replace_all(",", "") %>%
as.numeric()
sapply(pages, class)
pages$Helpful_votes <- pages$Helpful_votes %>%
str_replace_all(",", "") %>%
as.numeric()
pages$X._helpful <- pages$X._helpful %>%
str_replace_all("%","") %>%
as.numeric() %>%
./100
pages$X._helpful <- pages$X._helpful %>%
str_replace_all("%","") %>%
as.numeric() %>%
.[1]/100
getwd()
last_page <- function(reviews){
# starting page number
page_num <- mapply(floor, reviews/10)
return(page_num)
}
rm(initial_last_page())
rm(initial_last_page
)
rm(get_last_page
)
last_page <- last_page(pages$Reviews)
pages2 <- bind_cols(pages, last_page)
last_page <- last_page(pages$Reviews) %>% data.frame(last_page = .)
last_page <- data.frame(last_page = last_page)
pages2 <- bind_cols(pages, last_page)
View(pages2)
rm(pages2)
pages <- bind_cols(pages, last_page)
write.csv(pages, "reviewers.csv")
View(last_page)
?html
?GET
if(require(httr) == F) {install.packages("httr")
library(httr)}
rm(list = ls())
setwd("C:/Users/Ryan/Dropbox/RACHEL_RYAN/3_Code/R")
setwd("C:/Users/Ryan/Dropbox/RACHEL_RYAN/3_Code/R")
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
google <- html("http://google.com")
google
google2 <- html(httr::GET("http://google.com"))
google2
str(google)
str(google2)
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
page <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page=1"
html <- html(httr::GET(page))
review_links <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/*/div/a") %>%
html_attr("href") %>%
as.data.frame.character(stringsAsFactors = F)
url_name <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/td[2]/a[2]") %>%
html_attr("name") %>%
as.data.frame.character(stringsAsFactors = F)
user_name <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/td[3]/a/b") %>%
html_text() %>%
as.data.frame.character(stringsAsFactors = F)
metrics <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/td[contains(@class, 'crNum')]") %>%
html_text() %>%
matrix(nrow = 10, byrow = T) %>%
as.data.frame.matrix(stringsAsFactors = F)
metrics
colnames(metrics) <- c("Rank", "Reviews", "Helpful_votes", "%_helpful")
metrics
cols <- list(url_name = url_name,
user_name = user_name,
review_links = review_links)
# rename the columns and bind them together
cols <- Map(setNames, cols, names(cols)) %>% bind_cols()
review_links <- bind_cols(cols, metrics)
review_links
View(review_links)
View(review_links)
pages <- 10
pages <- paste(url, 1:pages, sep = "")
url <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
pages <- paste(url, 1:pages, sep = "")
pages
links <- lapply(pages, review_href)
links <- lapply(pages[1], review_href)
pages[1]
pages
review_href(pages[1])
review_href(pages[2])
View(review_href(pages[2]))
review_href(pages[1])
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
review_href(pages[1])
review_href(pages[1])
review_href(pages[3])
review_href(pages[4])
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
pages
url <- pages
pages <- 3
pages <- paste(url, 1:pages, sep = "")
pages
links <- lapply(pages, review_href)
page <- pages[1]
page
html <- html(httr::GET(page))
html
GET(page)
names(GET(page))
GET(page)["cookies"]
cookies(GET(page))
cookies(GET(page))[1]
cookies(GET(page))[2]
cookies(GET(page))[3]
cookies(GET(page))[4]
cookies(GET(page))[5]
cookies(GET(page))[6]
cookies(GET(page))[7]
names(cookies(GET(page)))
cookies(GET(page))[6]
cookies(GET(page))[7]
page
html <- html(httr::GET(page, set_cookies(`x-wl-uid` = "1Y8HqovKdWvU0B8aCAb+OmCx47dFPKPDL5H928B9195N0TH5+XVfq1Xf5LY0RtePOjf2IO/Bis0c=",
`session-id-time` = "2082787201l",
`session-id` = "185-1611110-8370107",
`ubid-main` = "178-0329605-2125753",
`session-token` = "qPAZoNOqcrCG+4dQY5a/tHYEbQbt1VP/AUpwePyme0IE28ZL7hFv7+6tY2Fo5XkMlA2oVYfgX37HtnBLIaSligYxZpvLs91Z2VxvoViFosEeCE/ZkXbOnMD23vPAsSqhu2w9lL6LPfEzgoc2wzcjtOttqWe8VHuCNBX5JP1qaI4QMIZ41yEuF66E++v/I97IBHHHRv9M44gHWKFm/2GV8y1bzFhhECVZqwruFzlW52zValyQHtsAKQmHdctjK78C")))
rm(review_links)
review_links <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/*/div/a") %>%
html_attr("href") %>%
as.data.frame.character(stringsAsFactors = F)
View(review_links)
url_name <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/td[2]/a[2]") %>%
html_attr("name") %>%
as.data.frame.character(stringsAsFactors = F)
View(url_name)
user_name <- html %>%
html_nodes(xpath = "//tr[contains(@id, 'reviewer')]/td[3]/a/b") %>%
html_text() %>%
as.data.frame.character(stringsAsFactors = F)
View(user_name)
rm(list = ls())
# get functions
setwd("C:/Users/Ryan/Dropbox/RACHEL_RYAN/3_Code/R")
source("reviewers.R")
# load the required packages
amazon_packages()
# time the process: takes around 8.4 minutes on my machine
start <- Sys.time()
# where do we want to start
pages <- "http://www.amazon.com/review/top-reviewers/ref=cm_cr_tr_link_2?ie=UTF8&page="
# grab Reviewer's review metrics
pages <- review_pages(pages, 1000)
# bind each data frame together: output should have 10,000 distinct url_names
pages <- bind_rows(pages)
# finish timer
end <- Sys.time() - start
GET("http://httpbin.org/cookies")
GET("http://httpbin.org/cookies")
cookies(GET("http://httpbin.org/cookies"))
GET("http://httpbin.org/cookies", set_cookies(a = 1, b = 2))
cookies(GET("http://httpbin.org/cookies"))
GET("http://httpbin.org/cookies", set_cookies(a = 1, b = 2))
GET("http://httpbin.org/cookies")
cookies(GET(page))
page
pages
page <- paste(pages,1:3,sep = "")
page
cookies(GET(page[1]))
coo <- GET(page, set_cookies(`x-wl-uid` = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
`session-id-time` = "2082787201l",
`session-id` = "187-8241568-2481532"))
coo <- GET(page[1], set_cookies(`x-wl-uid` = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
`session-id-time` = "2082787201l",
`session-id` = "187-8241568-2481532"))
cookies(coo)
coo <- GET(page[1], set_cookies(.cookies = c(`x-wl-uid` = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
`session-id-time` = "2082787201l",
`session-id` = "187-8241568-2481532")))
cookies(coo)
coo <- GET(page[1], set_cookies(.cookies = c(x-wl-uid = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
session-id-time = "2082787201l",
session-id = "187-8241568-2481532")))
coo <- GET(page[1], set_cookies(.cookies = c("x-wl-uid" = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
"session-id-time" = "2082787201l",
"session-id" = "187-8241568-2481532")))
cookies(coo)
coo1 <- GET(page[1], set_cookies(.cookies = c("x-wl-uid" = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
"session-id-time" = "2082787201l",
"session-id" = "187-8241568-2481532")))
coo2 <- GET(page[1], set_cookies(.cookies = c("x-wl-uid" = "1PoSVOBwOsg5yRnBmxp75F3EG4s9JfbIu00TspAoPwclHH1VOYYxd5++o2t/4tpurlaLmdWE8dyw=",
"session-id-time" = "2082787201l",
"session-id" = "187-8241568-2481532")))
identical(coo1,coo2)
identical(cookies(coo1),cookies(coo2))
cookies(coo1)
cookies(coo2)
